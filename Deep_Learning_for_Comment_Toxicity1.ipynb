{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ERNESTINE1990/Deep-Learning-for-Comment-Toxicity-Detection-with-Streamlit/blob/main/Deep_Learning_for_Comment_Toxicity1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f32de0a",
      "metadata": {
        "id": "3f32de0a"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "#Basic libraries for data manipulation and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re # for regular expressions text cleaning\n",
        "\n",
        "\n",
        "\n",
        "# Deep learning libraries - pytorch\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Hugging Face Transformers library\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "\n",
        "# Sklearn for model evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score,classification_report,hamming_loss,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abce7765",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "abce7765",
        "outputId": "5297f7cf-6a39-4ec6-f0d3-268061bd7213"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1715281531>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To read the csv file for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"
          ]
        }
      ],
      "source": [
        "# To read the csv file for training data\n",
        "df_train = pd.read_csv('/content/train.csv',encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a07e5e",
      "metadata": {
        "id": "04a07e5e"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42f77f8b",
      "metadata": {
        "id": "42f77f8b"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/test.csv',encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f3fc7c",
      "metadata": {
        "id": "52f3fc7c"
      },
      "outputs": [],
      "source": [
        "df_train.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5987e07a",
      "metadata": {
        "id": "5987e07a"
      },
      "outputs": [],
      "source": [
        "df_test.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97486a7",
      "metadata": {
        "id": "f97486a7"
      },
      "outputs": [],
      "source": [
        "df_train.describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbd3f5c",
      "metadata": {
        "id": "fcbd3f5c"
      },
      "outputs": [],
      "source": [
        "#shape of the train and test data\n",
        "df_train.shape\n",
        "df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da61886c",
      "metadata": {
        "id": "da61886c"
      },
      "source": [
        "1. Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6c55b4",
      "metadata": {
        "id": "3a6c55b4"
      },
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12822bc3",
      "metadata": {
        "id": "12822bc3"
      },
      "outputs": [],
      "source": [
        "# To verify the null values in the dataset\n",
        "df_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fda5de58",
      "metadata": {
        "id": "fda5de58"
      },
      "outputs": [],
      "source": [
        "# To verify duplicate values in the dataset\n",
        "\n",
        "df_train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c64540",
      "metadata": {
        "id": "45c64540"
      },
      "outputs": [],
      "source": [
        "# To remove the id column from the train and test data\n",
        "df_train.drop(['id'], axis=1, inplace=True)\n",
        "#df_test.drop(['id'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797ab1b7",
      "metadata": {
        "id": "797ab1b7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d3aecd",
      "metadata": {
        "id": "c2d3aecd"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f8ca3dd",
      "metadata": {
        "id": "8f8ca3dd"
      },
      "source": [
        "2.EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e603081b",
      "metadata": {
        "id": "e603081b"
      },
      "outputs": [],
      "source": [
        "#Comment length and its histogram plot\n",
        "df_train['comment_text'].str.len()\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.histplot(df_train['comment_text'].str.len(), bins=50, kde=True)\n",
        "plt.title('Comment Length Distribution')\n",
        "plt.xlabel('Comment Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ef4404",
      "metadata": {
        "id": "94ef4404"
      },
      "source": [
        " Comment Length Distribution\n",
        "\n",
        "X-axis (Comment Length): Ranges from 0 to about 6000 characters.\n",
        "\n",
        "Y-axis (Frequency): Peaks over 50,000 at the lowest lengths.\n",
        "\n",
        "The distribution is right-skewed:\n",
        "\n",
        "Most comments are very short (under 500 characters).\n",
        "\n",
        "The frequency drops steeply as comment length increases.\n",
        "\n",
        "A long tail indicates the presence of much longer comments, but these are rare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6df40c4",
      "metadata": {
        "id": "b6df40c4"
      },
      "outputs": [],
      "source": [
        "# correlation matrix\n",
        "\n",
        "data = df_train.drop(['comment_text'], axis=1)\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4225dff5",
      "metadata": {
        "id": "4225dff5"
      },
      "source": [
        "toxic & insult\t0.65\tStrong positive correlation. Comments labeled as \"toxic\" are often also marked as \"insult\".\n",
        "\n",
        "toxic & obscene\t0.68\tStrong positive correlation. Obscene language is commonly part of toxic comments.\n",
        "\n",
        "toxic & severe_toxic\t0.31\tModerate correlation. Not all toxic comments are considered severely toxic.\n",
        "\n",
        "toxic & threat\t0.16\tWeak correlation. Most toxic comments are not threats.\n",
        "\n",
        "toxic & identity_hate\t0.27\tWeak to moderate correlation. Some overlap exists but not strong.\n",
        "\n",
        " obscene & insult | 0.74 | Very strong correlation. Obscene comments are usually also insulting. |\n",
        "\n",
        "| obscene & severe_toxic | 0.40 | Moderate correlation. Severe toxicity may often include obscene words. |\n",
        "\n",
        "| severe_toxic & threat | 0.12 | Weak. Severe toxicity doesn't necessarily imply threats. |\n",
        "\n",
        "| threat & any other label | ~0.12 - 0.16 | Consistently low correlations. Threats are a more distinct category. |\n",
        "\n",
        "| identity_hate & others | Mostly ~0.20 - 0.34 | Weak to moderate. Some overlap but less predictable co-occurrence. |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80d4000",
      "metadata": {
        "id": "f80d4000"
      },
      "outputs": [],
      "source": [
        "# Rename the comment_text column to text\n",
        "#df_train.rename(columns={'comment_text': 'text'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb658040",
      "metadata": {
        "id": "cb658040"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a09c8f94",
      "metadata": {
        "id": "a09c8f94"
      },
      "outputs": [],
      "source": [
        "#define target features\n",
        "\n",
        "target_features = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54d2400e",
      "metadata": {
        "id": "54d2400e"
      },
      "outputs": [],
      "source": [
        "# calculate the feature counts and percentages\n",
        "\n",
        "feature_counts = df_train[target_features].sum()\n",
        "feature_precentages= (feature_counts / len(df_train)) * 100\n",
        "\n",
        "# Create a DataFrame for the feature counts and percentages\n",
        "feature_df = pd.DataFrame({\n",
        "    'Count': feature_counts,\n",
        "    'Percentage': feature_precentages\n",
        "})\n",
        "print(\" Feature distribution in the training data:\")\n",
        "print(feature_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c40291",
      "metadata": {
        "id": "83c40291"
      },
      "outputs": [],
      "source": [
        "# Plotting the feature distribution\n",
        "\n",
        "sns.barplot(x=feature_df.index.values, y='Count',data= feature_df)\n",
        "plt.title('Feature Distribution in Training Data')\n",
        "plt.ylabel('Number of comments')\n",
        "plt.xlabel('Features')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c8ff2a",
      "metadata": {
        "id": "f0c8ff2a"
      },
      "outputs": [],
      "source": [
        "#Check for comments with no toxic features\n",
        "\n",
        "non_toxic_comments = df_train[df_train[target_features].sum(axis=1) == 0]\n",
        "print(f\"\\n Number of non-toxic comments: {len(non_toxic_comments)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3d113d",
      "metadata": {
        "id": "5c3d113d"
      },
      "outputs": [],
      "source": [
        "# toxic comments\n",
        "toxic_comments1 = df_train[df_train[target_features].sum(axis=1) > 0]\n",
        "print(f\"\\n Number of toxic comments: {len(toxic_comments1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87daaf15",
      "metadata": {
        "id": "87daaf15"
      },
      "outputs": [],
      "source": [
        "# plot non_toxic_comments and toxic comments before training the model\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(['Non-Toxic Comments', 'Toxic Comments'], [len(non_toxic_comments), len(toxic_comments1)], color=['green', 'red'])\n",
        "plt.title('Number of Non-Toxic and Toxic Comments')\n",
        "plt.ylabel('Number of Comments')\n",
        "plt.xlabel('Comment Type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446fa6f3",
      "metadata": {
        "id": "446fa6f3"
      },
      "source": [
        "BERT\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers) is a powerful language representation model developed by Google in 2018.\n",
        "\n",
        "It's based on the Transformer architecture, and it's designed to understand the context of a word bidirectionally â€” meaning it looks at both the left and right context in a sentence.\n",
        "\n",
        "ðŸ” Key Features of BERT:\n",
        "\n",
        "Bidirectional context:\n",
        "\n",
        "Unlike previous models that read text left-to-right or right-to-left, BERT reads in both directions simultaneously.\n",
        "\n",
        "Pre-trained and fine-tuned:\n",
        "\n",
        " BERT is pre-trained on a large corpus (like Wikipedia), then fine-tuned for specific tasks (e.g., sentiment analysis, question answering).\n",
        "\n",
        "Transformer-based:\n",
        "\n",
        "Built using the encoder part of the Transformer architecture, allowing it to handle long-range dependencies in text.\n",
        "\n",
        "ðŸ§  How BERT Works:\n",
        "\n",
        "Pre-training tasks:\n",
        "\n",
        "Masked Language Modeling (MLM):\n",
        "\n",
        "Randomly masks words in the input and trains the model to predict them.\n",
        "\n",
        "Next Sentence Prediction (NSP):\n",
        "\n",
        "Trains the model to predict if one sentence follows another in context.\n",
        "\n",
        "Fine-tuning:\n",
        "\n",
        "After pre-training, BERT is adapted to specific tasks like classification, named entity recognition, or QA with a relatively small dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f2074c",
      "metadata": {
        "id": "35f2074c"
      },
      "source": [
        "3.Preprocessing and Tokenization ( BERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b764443",
      "metadata": {
        "id": "2b764443"
      },
      "source": [
        "3.1 Text Cleaning\n",
        "\n",
        "Text Cleaning for BERT Input\n",
        "Before feeding text into a BERT model (like bert-base-uncased), minimal preprocessing is usually needed because BERT uses WordPiece tokenization and is designed to handle \"messy\" real-world text. Here's what you typically need:\n",
        "\n",
        "âœ… Recommended Text Cleaning for BERT:\n",
        "Lowercasing (if using uncased models like bert-base-uncased)\n",
        "\n",
        "Remove excessive whitespace\n",
        "\n",
        "Replace HTML entities (&amp;, &lt;, etc.)\n",
        "\n",
        "Normalize unicode (e.g., unicodedata.normalize)\n",
        "\n",
        "Optionally: remove URLs/emails if irrelevant\n",
        "\n",
        "âŒ Do Not:\n",
        "Do not remove stop words (theyâ€™re important for context)\n",
        "\n",
        "Do not stem or lemmatize (BERT is subword-based)\n",
        "\n",
        "Do not aggressively strip punctuation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6afa2b1b",
      "metadata": {
        "id": "6afa2b1b"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7839ced",
      "metadata": {
        "id": "e7839ced"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.sample(n=10000, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9400b2",
      "metadata": {
        "id": "ad9400b2"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.sample(n=10000, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08c013c",
      "metadata": {
        "id": "f08c013c"
      },
      "outputs": [],
      "source": [
        "# 3.1 Text Cleaning (BERT)\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = str(text)  # Ensure text is a string\n",
        "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
        "    text = re.sub(r'\\s+', '', text).strip() # Remove mentions (To remove white spaces)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
        "\n",
        "    return text\n",
        "df_train['comment_text_cleaned'] = df_train['comment_text'].apply(clean_text)\n",
        "df_test['comment_text_cleaned'] = df_test['comment_text'].apply(clean_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c10f6ec2",
      "metadata": {
        "id": "c10f6ec2"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d923ba",
      "metadata": {
        "id": "03d923ba"
      },
      "source": [
        "3.2 Tokenization with BERT tokenizer\n",
        "\n",
        "Tokenization with the BERT tokenizer is a key step in preparing text data for input into BERT models. Here's a concise overview of how it works:\n",
        "\n",
        "ðŸ”¹ What is Tokenization?\n",
        "\n",
        "Tokenization is the process of splitting text into smaller units called tokens. BERT uses WordPiece tokenization, which breaks words into subword units.\n",
        "\n",
        "ðŸ”¹ BERT Tokenizer Characteristics\n",
        "\n",
        "Lowercasing (optional): Converts text to lowercase (e.g., \"Hello\" â†’ \"hello\") if using the bert-base-uncased model.\n",
        "\n",
        "WordPiece Tokenizer: Splits unknown or rare words into subwords, prefixed with ## if they're a continuation of a word.\n",
        "\n",
        "Special Tokens:\n",
        "\n",
        "[CLS]: Classification token added at the beginning.\n",
        "\n",
        "[SEP]: Separator token used between sentence pairs or at the end of a single sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c57b6f4d",
      "metadata": {
        "id": "c57b6f4d"
      },
      "outputs": [],
      "source": [
        "# 3.2 Tokenization with BERT tokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#tokenizer = BertTokenizer.from_pretrained('C:/Users/mosel/.cache/huggingface/hub/models--bert-base-uncased')\n",
        "\n",
        "sample_text =\"Sample comment for tokenization\"\n",
        "\n",
        "encoded_sample = tokenizer.encode_plus(\n",
        "    sample_text,\n",
        "    add_special_tokens=True,\n",
        "    max_length=35,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\"\"\"def tokenize_text(text):\n",
        "    return tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,  # Add [CLS] and [SEP] tokens\n",
        "        max_length=50,  # Maximum length of the sequence\n",
        "        padding='max_length',  # Pad to max_length\n",
        "        truncation=True,  # Truncate if longer than max_length\n",
        "        return_tensors='pt'  # Return PyTorch tensors\n",
        "    )\"\"\"\n",
        "\"\"\"print(\"\\nSample Tokenization:\")\n",
        "print(f\"Text: {sample_text}\")\n",
        "print(f\"Tokens: {tokenizer.tokenize(sample_text)}\")\n",
        "print(f\"Input IDs: {tokenizer.encode(sample_text, add_special_tokens=True)}\")\n",
        "print(f\"Attention Mask: {tokenizer.encode(sample_text, add_special_tokens=True, padding='max_length', truncation=True, max_length=50)}\") # 1 for real tokens, 0 for padding\"\"\"\n",
        "\n",
        "\n",
        "print(\"\\nSample Tokenization:\")\n",
        "print(f\"Text: {sample_text}\")\n",
        "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(encoded_sample['input_ids'][0])}\")\n",
        "print(f\"Input IDs: {encoded_sample['input_ids']}\")\n",
        "print(f\"Attention Mask: {encoded_sample['attention_mask']}\") # 1 for real tokens, 0 for padding\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "defe9ce7",
      "metadata": {
        "id": "defe9ce7"
      },
      "source": [
        "3.3 Creating Pytorch Dataset and DataLoader\n",
        "\n",
        "Creating a Dataset and DataLoader in PyTorch is essential for efficiently handling and feeding data into a model during training or evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe01552f",
      "metadata": {
        "id": "fe01552f"
      },
      "outputs": [],
      "source": [
        "# 3.3 Creating Pytorch Dataset and DataLoader\n",
        "\n",
        "class ToxicCommentDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, comments, targets, tokenizer, max_length):\n",
        "\n",
        "        self.comments = comments\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "    def __getitem__(self, idx):\n",
        "        comment = self.comments[idx]\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        # Tokenize the comment\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Return the encoded inputs and target\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(target, dtype=torch.float)\n",
        "        }\n",
        "#3.4 preparing the dataset and dataloader\n",
        "# Define X and y\n",
        "X = df_train['comment_text_cleaned'].values\n",
        "y = df_train[target_features].values\n",
        "\n",
        "# split the data into training and validation sets\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) # Seed = 42 for reproducibility\n",
        "\n",
        "# Print the Train size and validation size\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "\n",
        "# Create the datasets\n",
        "\n",
        "train_dataset = ToxicCommentDataset(X_train, y_train, tokenizer, max_length= 128)# max_length can be adjusted based on the average length of comments\n",
        "val_dataset = ToxicCommentDataset(X_val, y_val, tokenizer, max_length= 128)\n",
        "\n",
        "# Create the DataLoaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Check the first batch of data\n",
        "\n",
        "data = next(iter(train_loader))\n",
        "print(\"\\n sample batch data:\")\n",
        "print(f\"Input IDs: {data['input_ids'].shape}\")\n",
        "print(f\"Attention Mask: {data['attention_mask'].shape}\")\n",
        "print(f\"Targets: {data['targets'].shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c22b6710",
      "metadata": {
        "id": "c22b6710"
      },
      "source": [
        "4.Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "115e5b15",
      "metadata": {
        "id": "115e5b15"
      },
      "source": [
        "BertForSequenceClassification = BERT + classification head\n",
        "\n",
        "Automatically handles loss computation if labels are provided\n",
        "\n",
        "Use with tokenized inputs: input_ids, attention_mask, and optional labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a3a3d80",
      "metadata": {
        "id": "4a3a3d80"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained BERT model for sequence classification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(target_features))\n",
        "\n",
        "# Move the model to designated device (GPU or CPU)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model is running on: {device}\")\n",
        "\n",
        "print(\"\\n Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e40bd46",
      "metadata": {
        "id": "7e40bd46"
      },
      "source": [
        "5.Model Training\n",
        "\n",
        "5.1 Setup Optimizer and Scheduler\n",
        "\n",
        "The AdamW optimizer is the default optimizer used in most modern BERT implementations because it effectively handles weight decay.\n",
        "\n",
        "ðŸ§  Why AdamW with BERT?\n",
        "\n",
        "BERT has LayerNorm and bias terms that should not have weight decay.\n",
        "\n",
        "AdamW separates weight decay from gradient updates, which is correct behavior for L2 regularization in transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ecb038",
      "metadata": {
        "id": "71ecb038"
      },
      "outputs": [],
      "source": [
        "#5.1 Optimizer and learning rate scheduler\n",
        "\n",
        "# Optimizer\n",
        "# (learning_rate(lr) = 2e-5 is a common choice for fine-tuning BERT)\n",
        "# (Epsilon (eps) = 1e-8 is a small value to prevent division by zero in AdamW optimizer)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Total number of training steps\n",
        "\n",
        "total_steps = len(train_loader) * 3  # Assuming 5 epochs ( Epochs = 3)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,  # No warmup steps\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "# Loss function #Sigmoid activation + Binary Cross Entropy (BCE) loss\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)  # Binary Cross-Entropy Loss for multi-label classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a1c26ea",
      "metadata": {
        "id": "8a1c26ea"
      },
      "source": [
        "5.2 Training Loop\n",
        "\n",
        "ðŸ“Œ Key Concepts\n",
        "\n",
        "Step\t                Purpose\n",
        "model.train()\t      -     Enables training behaviors like dropout\n",
        "\n",
        "optimizer.zero_grad() -\tClears previously accumulated gradients\n",
        "\n",
        "loss.backward()\t      -    Computes gradients via backpropagation\n",
        "\n",
        "optimizer.step()\t  -    Updates model parameters using optimizer\n",
        "\n",
        "scheduler.step()\t  -    Adjusts learning rate (optional)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3184c7f",
      "metadata": {
        "id": "c3184c7f"
      },
      "outputs": [],
      "source": [
        "# 5.2 Training Loop\n",
        "\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, Scheduler):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    num_batches = len(data_loader)\n",
        "\n",
        "    for i , data in enumerate(data_loader):\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        targets = data['targets'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits # logits are the raw output scores from the model\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(logits, targets)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad() # Reset gradients\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Clip gradients to prevent exploding gradients\n",
        "        optimizer.step()\n",
        "        Scheduler.step()\n",
        "\n",
        "        # Print progress every 100 batches\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Batch {i + 1}/{num_batches}, Loss: {loss.item():.4f}\")\n",
        "    avg_train_loss = total_loss / num_batches\n",
        "    print(f\"Average Loss for this epoch: {avg_train_loss:.4f}\")\n",
        "    return avg_train_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6083c75",
      "metadata": {
        "id": "c6083c75"
      },
      "source": [
        "5.3 Evaluation loop\n",
        "\n",
        "The evaluation loop  runs the model on a validation or test dataset without\n",
        "updating weights to measure performance.\n",
        "\n",
        "âœ… Purpose\n",
        "\n",
        "Check model performance during or after training.\n",
        "\n",
        "Compute metrics: loss, accuracy, F1, etc.\n",
        "\n",
        "Ensure model.eval() is called to disable dropout, etc.\n",
        "\n",
        "No gradients: We use torch.no_grad() for efficiency.\n",
        "\n",
        "ðŸ“Œ Key Concepts\n",
        "\n",
        "Step\t                        Description\n",
        "\n",
        "model.eval()\t            -    Disables dropout, layernorm updates\n",
        "\n",
        "torch.no_grad()\t            -   Speeds up computation, avoids storing gradients\n",
        "\n",
        "loss_fn(outputs, labels)    -   Same loss as training (e.g., BCEWithLogitsLoss)\n",
        "\n",
        "torch.sigmoid(outputs) > 0.5 -\tConverts logits to binary predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3ab193",
      "metadata": {
        "id": "2e3ab193"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, hamming_loss\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, target_features):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "    num_batches = len(data_loader)\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for data in data_loader:\n",
        "            input_ids = data['input_ids'].to(device)\n",
        "            attention_mask = data['attention_mask'].to(device)\n",
        "            targets = data['targets'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(logits, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Store predictions and true labels\n",
        "            probs = torch.sigmoid(logits)\n",
        "            all_predictions.append(probs.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "        avg_eval_loss = total_loss / num_batches\n",
        "        print(f\"Average Loss for this epoch: {avg_eval_loss:.4f}\")\n",
        "\n",
        "        # Concatenate results from all batches\n",
        "        all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "        all_targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "        # Calculate metrics\n",
        "        roc_auc_scores = {}\n",
        "        mean_roc_auc = 0\n",
        "\n",
        "        try:\n",
        "            for i, label_name in enumerate(target_features):\n",
        "                if len(np.unique(all_targets[:, i])) > 1:\n",
        "                    roc_auc_scores[label_name] = roc_auc_score(all_targets[:, i], all_predictions[:, i])\n",
        "                else:\n",
        "                    roc_auc_scores[label_name] = np.nan\n",
        "\n",
        "            # Calculate mean AUC, ignoring NaNs\n",
        "            mean_roc_auc = np.nanmean(list(roc_auc_scores.values()))\n",
        "\n",
        "            print(f\"Mean ROC AUC: {mean_roc_auc:.4f}\")\n",
        "            print(\"Individual ROC AUC Scores:\")\n",
        "            for name, score in roc_auc_scores.items():\n",
        "                print(f\"{name}: {score:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Could not calculate ROC AUC: {e}\")\n",
        "\n",
        "        # Calculate Hamming Loss\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (all_predictions > threshold).astype(int)\n",
        "        hamming = hamming_loss(all_targets, binary_predictions)\n",
        "        print(f\"Hamming Loss: {hamming:.4f}\")\n",
        "\n",
        "        return avg_eval_loss, mean_roc_auc, hamming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae3e98f6",
      "metadata": {
        "id": "ae3e98f6"
      },
      "source": [
        "5.4 Execute training and Evaluation Loop\n",
        "\n",
        "Trains a PyTorch model over multiple epochs.\n",
        "\n",
        "Tracks and saves the best model (based on validation ROC AUC).\n",
        "\n",
        "Loads the best model after training for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61bd5dcc",
      "metadata": {
        "id": "61bd5dcc"
      },
      "outputs": [],
      "source": [
        "# 5.4 Execute training and Evaluation\n",
        "\n",
        "result = {'train_loss': [],'eval_loss' : [],'eval_roc_auc':[],'eval_hamming':[]}\n",
        "best_roc_auc = -1\n",
        "best_model_state = None\n",
        "print(\"\\n Training Start\")\n",
        "for epoch in range(3):\n",
        "     # Epoch = 3\n",
        "    print(f'\\n-----Epoch {epoch + 1}/{3}-----')\n",
        "\n",
        "    train_loss=train_epoch(model,train_loader,loss_fn,optimizer, device,scheduler)\n",
        "\n",
        "    result['train_loss'].append(train_loss)\n",
        "\n",
        "    print(f\"\\n ----- validation Epoch {epoch + 1}-----\")\n",
        "\n",
        "    eval_loss, eval_roc_auc , eval_hamming = eval_model(model,val_loader,loss_fn,device,target_features)\n",
        "\n",
        "    result['eval_loss'].append(eval_loss)\n",
        "    result['eval_roc_auc'].append(eval_roc_auc)\n",
        "    result['eval_hamming'].append(eval_hamming)\n",
        "\n",
        "#Save the best model based on validation ROC AUC\n",
        "\n",
        "    if eval_roc_auc > best_roc_auc:\n",
        "\n",
        "      best_roc_auc = eval_roc_auc\n",
        "      best_model_state = model.state_dict()\n",
        "      torch.save(best_model_state, 'best_model_state.bin')\n",
        "      print(f\"----New best model saved with ROC AUC:{best_roc_auc:.4f}----\")\n",
        "print(\"\\n Training Finished.\")\n",
        "print(f\"Best Validation ROC AUC: {best_roc_auc:4f}\")\n",
        "\n",
        "#Load the best model state for prediction\n",
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(\"Load best model state for prediction.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a88dcb",
      "metadata": {
        "id": "39a88dcb"
      },
      "outputs": [],
      "source": [
        "#5.5 Plot Training History\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(1,3+1),result['train_loss'],label='Train Loss')\n",
        "plt.plot(range(1,3+1),result['eval_loss'],label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(1,3+1),result['eval_roc_auc'],label='Validation Mean ROC AUC')\n",
        "plt.title('Mean ROC AUC OVER Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean ROC AUC')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd35928",
      "metadata": {
        "id": "9dd35928"
      },
      "source": [
        "6.Prediction on Test Set\n",
        "\n",
        "Use the trained (best) model to generate predictions on the unseen test data.\n",
        "\n",
        "6.1 Prepare test Data Loader\n",
        "\n",
        "\n",
        "Create a Dataset and DataLoader for the test set, similar to the training/\n",
        "\n",
        "validation sets, but without labels.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a236e9",
      "metadata": {
        "id": "82a236e9"
      },
      "outputs": [],
      "source": [
        "# Dataset and DataLoader for the test set\n",
        "\n",
        "class TestCommentDataset(Dataset):\n",
        "    def __init__(self, comments, tokenizer, max_len):\n",
        "        self.comments = comments\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment = str(self.comments[item])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        }\n",
        "\n",
        "test_texts = df_test['comment_text_cleaned'].values\n",
        "test_dataset = TestCommentDataset(test_texts, tokenizer, 128)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58c9d89",
      "metadata": {
        "id": "a58c9d89"
      },
      "source": [
        "6.2 Generate Predictions\n",
        "\n",
        "Run the model in evaluation mode on the test data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46af327e",
      "metadata": {
        "id": "46af327e"
      },
      "outputs": [],
      "source": [
        "def predict(model, data_loader, device):\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    print(\"\\nGenerating predictions on test data...\")\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            input_ids = data[\"input_ids\"].to(device)\n",
        "            attention_mask = data[\"attention_mask\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "            probs = torch.sigmoid(logits) # Convert logits to probabilities (0-1 range)\n",
        "            predictions.append(probs.cpu().numpy())\n",
        "\n",
        "    return np.concatenate(predictions, axis=0)\n",
        "\n",
        "test_predictions = predict(model, test_dataloader, device)\n",
        "print(\"Predictions generated successfully.\")\n",
        "print(\"Shape of predictions:\", test_predictions.shape) # Should be (num_test_samples, num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c350084c",
      "metadata": {
        "id": "c350084c"
      },
      "source": [
        "6.3 Format submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0d7afd",
      "metadata": {
        "id": "ad0d7afd"
      },
      "outputs": [],
      "source": [
        "#target_features\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission_df = pd.DataFrame(test_predictions, columns=target_features)\n",
        "submission_df['id'] = df_test['id'] # Add the id column\n",
        "\n",
        "# Reorder columns to match sample_submission.csv format ('id' first, then label columns)\n",
        "submission_df = submission_df[['id'] + target_features]\n",
        "\n",
        "print(\"\\nSubmission DataFrame Head:\")\n",
        "print(submission_df.head())\n",
        "\n",
        "# Save to CSV\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\n Submission file 'submission.csv' created successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W-Kyazw8LyTj",
      "metadata": {
        "id": "W-Kyazw8LyTj"
      },
      "outputs": [],
      "source": [
        "pip install streamlit transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d84f334",
      "metadata": {
        "id": "0d84f334"
      },
      "outputs": [],
      "source": [
        "%%writefile toxic_app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "\n",
        "# Define the target labels\n",
        "target_features = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# Load tokenizer and model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(target_features))\n",
        "    model.load_state_dict(torch.load('best_model_state.bin', map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"ðŸ§ª Toxic Comment Classifier\")\n",
        "st.write(\"Enter a comment below to check its toxicity level.\")\n",
        "\n",
        "user_input = st.text_area(\"âœï¸ Your Comment\", height=150)\n",
        "\n",
        "if st.button(\"ðŸ” Predict\"):\n",
        "    if not user_input.strip():\n",
        "        st.warning(\"Please enter a comment.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing...\"):\n",
        "            encoded = tokenizer.encode_plus(\n",
        "                user_input,\n",
        "                add_special_tokens=True,\n",
        "                max_length=128,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            input_ids = encoded['input_ids']\n",
        "            attention_mask = encoded['attention_mask']\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                probs = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
        "\n",
        "            st.success(\"Prediction complete!\")\n",
        "\n",
        "            st.subheader(\"ðŸ§¾ Toxicity Scores\")\n",
        "            for label, score in zip(target_features, probs):\n",
        "                st.write(f\"**{label}**: {score:.4f} {'âœ…' if score < 0.5 else 'âš ï¸'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef7b16d",
      "metadata": {
        "id": "fef7b16d"
      },
      "outputs": [],
      "source": [
        "#pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a05ab326",
      "metadata": {
        "id": "a05ab326"
      },
      "outputs": [],
      "source": [
        "#Make sure to install these in your environment:\n",
        "\n",
        "\n",
        "#!pip install streamlit transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "929f4ec7",
      "metadata": {
        "id": "929f4ec7"
      },
      "outputs": [],
      "source": [
        "#In the terminal, run:\n",
        "#You can't run the Streamlit UI inside a Jupyter Notebook.\n",
        "# But you can launch it in a new browser tab from a notebook cell using:\n",
        "#e.g This will start the Streamlit app and give you a link like http://localhost:8501.\n",
        "\n",
        "\n",
        "\n",
        "!streamlit run toxic_app.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}